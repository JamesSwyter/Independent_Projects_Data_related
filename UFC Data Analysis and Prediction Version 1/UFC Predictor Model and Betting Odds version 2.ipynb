{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152689f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"Documents/ufc_master.csv\")\n",
    "\n",
    "#Drop betting odds, these will be predicted later\n",
    "data = data.drop(columns=['R_odds','B_odds'])\n",
    "\n",
    "#Drop missing values\n",
    "data = data.dropna()\n",
    "\n",
    "#Switch Winner column to binary values\n",
    "data['Winner'].replace(['Red','Blue'],[1,0], inplace=True)\n",
    "\n",
    "#Separate results from predictor variables\n",
    "Winner = data.iloc[:,0]\n",
    "Variables = data.iloc[:,1:]\n",
    "\n",
    "#Transform categorical variables to dummy columns\n",
    "Variables = pd.get_dummies(Variables)\n",
    "\n",
    "#data.info()\n",
    "#data.head()\n",
    "#Variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae71a788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161825726141079"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the data and Fitting the Model\n",
    "#Using PCA since several of the variables will be highly correlated with each other\n",
    "#Score the first time was .601\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "Variables_Train, Variables_Test, Winner_Train, Winner_Test = train_test_split(Variables, Winner)\n",
    "\n",
    "pipe = Pipeline([('pca', PCA()),('scale', StandardScaler()),('log_reg', LogisticRegression())])\n",
    "\n",
    "pipe.fit(Variables_Train, Winner_Train).score(Variables_Test, Winner_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17872a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.656014\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3671\n",
      "Model:                          Logit   Df Residuals:                     3653\n",
      "Method:                           MLE   Df Model:                           17\n",
      "Date:                Tue, 24 Oct 2023   Pseudo R-squ.:                 0.03245\n",
      "Time:                        12:08:50   Log-Likelihood:                -2408.2\n",
      "converged:                       True   LL-Null:                       -2489.0\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.323e-25\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0241      0.040     -0.601      0.548      -0.103       0.054\n",
      "x2            -0.0845      0.024     -3.498      0.000      -0.132      -0.037\n",
      "x3            -0.0413      0.028     -1.482      0.138      -0.096       0.013\n",
      "x4             0.0147      0.028      0.529      0.597      -0.040       0.069\n",
      "x5             0.0131      0.016      0.842      0.400      -0.017       0.044\n",
      "x6             0.0044      0.005      0.923      0.356      -0.005       0.014\n",
      "x7            -0.0362      0.025     -1.465      0.143      -0.085       0.012\n",
      "x8             0.0009      0.026      0.033      0.973      -0.051       0.052\n",
      "x9            -0.0154      0.030     -0.523      0.601      -0.073       0.042\n",
      "x10            0.0038      0.007      0.558      0.577      -0.010       0.017\n",
      "x11           -0.0165      0.005     -3.159      0.002      -0.027      -0.006\n",
      "x12           -0.0410      0.007     -5.599      0.000      -0.055      -0.027\n",
      "x13           -0.0029      0.002     -1.762      0.078      -0.006       0.000\n",
      "x14           -0.0631      0.045     -1.392      0.164      -0.152       0.026\n",
      "x15           -0.1140      0.022     -5.112      0.000      -0.158      -0.070\n",
      "x16           -0.5432      0.288     -1.887      0.059      -1.107       0.021\n",
      "x17            0.4812      0.071      6.775      0.000       0.342       0.620\n",
      "x18            0.2811      0.042      6.665      0.000       0.198       0.364\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#Data has a lot of multicollinearity. This new dataset focuses on differentials between opponents, which should have less\n",
    "#multicollinearity. This logistic regression model can show the statistical signficance of individual variables\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"Documents/ufc_master_differential.csv\")\n",
    "\n",
    "#Drop missing values\n",
    "data = data.dropna()\n",
    "\n",
    "#Switch Winner column to binary values\n",
    "data['Winner'].replace(['Red','Blue'],[1,0], inplace=True)\n",
    "\n",
    "#Separate results from predictor variables, and don't include betting odds\n",
    "Winner = data.iloc[:,0]\n",
    "Variables = data.iloc[:,3:]\n",
    "\n",
    "#Transform categorical variables to dummy columns\n",
    "Variables = pd.get_dummies(Variables)\n",
    "\n",
    "Variables_Train, Variables_Test, Winner_Train, Winner_Test = train_test_split(Variables, Winner)\n",
    "\n",
    "Winner_Train = np.asarray(Winner_Train)\n",
    "Variables_Train=np.asarray(Variables_Train)\n",
    "\n",
    "logit_model=sm.Logit(Winner_Train, Variables_Train)\n",
    "result = logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef44d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6021241830065359"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This time using a custom dataset that focuses on statistically significant variables\n",
    "\n",
    "data = pd.read_csv(\"Documents/ufc_master_custom_vers1.csv\")\n",
    "\n",
    "#Drop missing values\n",
    "data = data.dropna()\n",
    "\n",
    "#Switch Winner column to binary values\n",
    "data['Winner'].replace(['Red','Blue'],[1,0], inplace=True)\n",
    "\n",
    "#Separate results from predictor variables\n",
    "Winner = data.iloc[:,0]\n",
    "Variables = data.iloc[:,1:]\n",
    "\n",
    "#No PCA this time, variables should not have multicollinearity\n",
    "Variables_Train, Variables_Test, Winner_Train, Winner_Test = train_test_split(Variables, Winner)\n",
    "\n",
    "pipe = Pipeline([('scale', StandardScaler()),('log_reg', LogisticRegression())])\n",
    "\n",
    "pipe.fit(Variables_Train, Winner_Train).score(Variables_Test, Winner_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bae28a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
